{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6657f14",
   "metadata": {},
   "source": [
    "Acquiring and Processing Information on the World's Largest Banks\n",
    "===========================\n",
    "_Instructions and dataset taken from IBM's **[Python Project for Data Engineering](https://www.coursera.org/learn/python-project-for-data-engineering)** in Coursera_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e087133",
   "metadata": {},
   "source": [
    "# Scenario\n",
    "- apply data-cleaning skills to process information about marketing campaigns run by a bank\n",
    "-modify values, add new features, convert data types as required by the client\n",
    "- save data into multiple files\n",
    "\n",
    "You have been hired as a data engineer by research organization. Your boss has asked you to create a code that can be used to compile the list of the top 10 largest banks in the world ranked by market capitalization in billion USD.\n",
    "\n",
    "Further, the data needs to be transformed and stored in GBP, EUR andINR as well, in accordance with the exchange rate information that has been made available to you as a CSV file.\n",
    "\n",
    "The information required are:\n",
    "\n",
    "| Column Name | Description |\n",
    "| ----------- | ----------- |\n",
    "| `Name` | Name of the bank as listed in target website|\n",
    "| `MC_USD_Billion` | Market capitalization amount in billions of **US Dollar**, as listed in target website |\n",
    "| `MC_GBP_Billion` | Market capitalization amount in billions of **Great Britain Pound**, converted from `MC_USD_Billion` using the given [exchange_rate.csv](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv) |\n",
    "| `MC_EUR_Billion` | Market capitalization amount in billions of **Euro**, converted from `MC_USD_Billion` using the given [exchange_rate.csv](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv) |\n",
    "| `MC_INR_Billion` | Market capitalization amount in billions of **Indian Rupee**, converted from `MC_USD_Billion` using the given [exchange_rate.csv](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv) |\n",
    "\n",
    "The processed information table is to be saved locally in a CSV format and as a database table.\n",
    "\n",
    "Your job is to create an automated system to generate this information so that the same can be executed in every financial quarter to prepare the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b57a4",
   "metadata": {},
   "source": [
    "# Prerequisite Steps\n",
    "## 1. Gather the other required data file/s\n",
    "```\n",
    "cd data\n",
    "wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\n",
    "```\n",
    "\n",
    "> [!NOTE]\n",
    "> In case of unavailability, a snapshot of `exchange_rate.csv` is also available in the root directory.\n",
    "> Date of snapshot: `2025 Apr 11`\n",
    "\n",
    "## 2. Install required libraries\n",
    "```\n",
    "python -m pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f372b",
   "metadata": {},
   "source": [
    "# Project Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e2edad3c-8286-4983-b5b7-35d94fd78023",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 54,
    "lastExecutedAt": 1743072209134,
    "lastExecutedByKernel": "d357bc14-fd68-443d-a7db-477e48b013a5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\nimport numpy as np\n\n# Start coding here..."
   },
   "outputs": [],
   "source": [
    "# for data frame compilation and utilities\n",
    "import pandas as pd\n",
    "\n",
    "# for numerical computations and types\n",
    "import numpy as np\n",
    "\n",
    "# for deleting the output files, if existing, before the whole ETL process is run\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6217bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete output files, if existing, to start each run with a clean slate\n",
    "for f in glob.glob(\"output/*.csv\"):\n",
    "    os.remove(f)\n",
    "\n",
    "for f in glob.glob(\"output/*.db\"):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893234f",
   "metadata": {},
   "source": [
    "## Task 1: Create the Logging method\n",
    "Write a function `log_progress()` to log the progress of the code at different stages in a file\n",
    "`code_log.txt`. Use the list of log points provided to create logentries as every stage of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc72621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbdc72de",
   "metadata": {},
   "source": [
    "## Task 2: Extraction\n",
    "Extract the tabular information from the given URL under the heading 'By market capitalization' and save it to a dataframe.\n",
    "\n",
    "1. Inspect the webpage and identify the position and pattern of the tabular information in the HTML code\n",
    "2. Write the code for a function `extract()` to perform the required data extraction.\n",
    "3. Execute a function call to `extract()` to verify the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bab472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a81a28",
   "metadata": {},
   "source": [
    "## Task 3: Transformation\n",
    "Transform the dataframe by adding columns for Market Capitalization in GBP, EUR and INR, rounded to 2 decimal places, based on the exchange rateinformation shared as a CSV file.\n",
    "1. Write the code for a function `transform()` to perform the said task.\n",
    "2. Execute a function call to `transform()` and verify the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea5f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a495ffaf",
   "metadata": {},
   "source": [
    "## Task 4: Loading to CSV\n",
    "Load the transformed dataframe to an output CSV file. Write a function `load_to_csv()`, execute a function call and verify the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de093874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e10f961a",
   "metadata": {},
   "source": [
    "## Task 5: Loading to DB\n",
    "Load the transformed dataframe to an SQL database server as a table. Write a function `load_to_db()`, execute a function call and verify the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51f853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e7da154",
   "metadata": {},
   "source": [
    "## Task 6: Validation of output in DB\n",
    "Run queries on the database table. Write a function `load_to_db()`, execute a given set of queries and verify the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b607e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "538342c1",
   "metadata": {},
   "source": [
    "## Task 7: Validation of output log\n",
    "Verify that the log entries have been completed at all stages by checking the contents of the file\n",
    "`code_log.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d3770-7ce3-4af0-803a-367517b550b0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 84,
    "lastExecutedAt": 1743072209218,
    "lastExecutedByKernel": "d357bc14-fd68-443d-a7db-477e48b013a5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "df = pd.read_csv(\"bank_marketing.csv\")\n\nfor col in [\"credit_default\", \"mortgage\", \"previous_outcome\", \"campaign_outcome\"]:\n    print(col)\n    print(\"--------------\")\n    print(df[col].value_counts())",
    "outputsMetadata": {
     "0": {
      "height": 500,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3874271c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "<!-- We have successfully extracted specific data from the given dataset `bank_marketing.csv` and performed the required data cleaning. Furthermore, we have added new columns whose values are derived from the given dataset. Finally, we were able to export them into three (3) output CSV files. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea08e64",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "## Course Instructors\n",
    "- Ramesh Sannareddy\n",
    "- Joseph Santarcangelo\n",
    "- Abhishek Gagneja\n",
    "## Course Offered By\n",
    "* [IBM Skills Network](https://www.coursera.org/partners/ibm-skills-network)"
   ]
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
